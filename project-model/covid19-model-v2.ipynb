{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6c0bebf78790>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMarkdown\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m#import missingno as msno\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "#import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from IPython.display import Markdown as md\n",
    "import seaborn as sb\n",
    "#import missingno as msno\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# set to show all columns\n",
    "pd.set_option('display.max_columns', 55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_var(var='positive'):\n",
    "    \"\"\"\n",
    "    Plots a bar chart of the given variable over the date range\n",
    "    \"\"\"\n",
    "    assert type(var)==str, \"Expected string as the variable name\"\n",
    "\n",
    "    y = df[var]\n",
    "    x = df['date']\n",
    "    plt.figure(figsize=(20,4))\n",
    "    plt.title(\"Plot of \\\"{}\\\" for New York\".format(var),fontsize=18)\n",
    "    plt.plot(x,y,color='navy')\n",
    "    plt.grid(False)\n",
    "    plt.xticks(fontsize=14,rotation=45)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "def plot_hist(var='positiveIncrease'):\n",
    "    \"\"\"\n",
    "    Plots a bar chart of the given variable over the date range\n",
    "    \"\"\"\n",
    "    assert type(var)==str, \"Expected string as the variable name\"\n",
    "\n",
    "    y = df[var]\n",
    "    plt.figure(figsize=(20,4))\n",
    "    plt.title(\"Plot of \\\"{}\\\" for New York\".format(var),fontsize=18)\n",
    "    plt.hist(y,color='royalblue')\n",
    "    plt.grid(False)\n",
    "    plt.xticks(fontsize=14,rotation=45)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "def add_sevenday_newCases(df):\n",
    "\n",
    "    df['sevenDayAvg_newCases'] = 'NA'\n",
    "\n",
    "    for i in range(0, len(df['positiveIncrease'])):\n",
    "        if i < 7:\n",
    "            df['sevenDayAvg_newCases'][i] = 0\n",
    "        else :\n",
    "            weekly = []\n",
    "            for y in range(0,7):\n",
    "                weekly.append(df['positiveIncrease'][i-y])\n",
    "            df['sevenDayAvg_newCases'][i] = round(sum(weekly) / 7)\n",
    "    return df\n",
    "\n",
    "# 7 days moving average for hospitalization\n",
    "def add_sevenday_hospitalize(df):\n",
    "\n",
    "    df['sevenDayAvg_hospitalize'] = 'NA'\n",
    "\n",
    "    for i in range(0, len(df['hospitalizedIncrease'])):\n",
    "        if i < 7:\n",
    "            df['sevenDayAvg_hospitalize'][i] = 0\n",
    "        else :\n",
    "            weekly = []\n",
    "            for y in range(0,7):\n",
    "                weekly.append(df['hospitalizedIncrease'][i-y])\n",
    "            df['sevenDayAvg_hospitalize'][i] = round(sum(weekly) / 7)\n",
    "    return df\n",
    "\n",
    "# 7 days moving average for Death\n",
    "def add_sevenday_death(df):\n",
    "\n",
    "    df['sevenDayAvg_death'] = 'NA'\n",
    "\n",
    "    for i in range(0, len(df['deathIncrease'])):\n",
    "        if i < 7:\n",
    "            df['sevenDayAvg_death'][i] = 0\n",
    "        else :\n",
    "            weekly = []\n",
    "            for y in range(0,7):\n",
    "                weekly.append(df['deathIncrease'][i-y])\n",
    "            df['sevenDayAvg_death'][i] = round(sum(weekly) / 7)\n",
    "    return df\n",
    "\n",
    "# 7 days moving average for Test Result\n",
    "def add_sevenday_testResult(df):\n",
    "\n",
    "    df['sevenDayAvg_testResult'] = 'NA'\n",
    "\n",
    "    for i in range(0, len(df['totalTestResultsIncrease'])):\n",
    "        if i < 7:\n",
    "            df['sevenDayAvg_testResult'][i] = 0\n",
    "        else :\n",
    "            weekly = []\n",
    "            for y in range(0,7):\n",
    "                weekly.append(df['totalTestResultsIncrease'][i-y])\n",
    "            df['sevenDayAvg_testResult'][i] = round(sum(weekly) / 7)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# API Hosting Suppose to End 5/1/2021\n",
    "url=\"https://api.covidtracking.com/v1/states/ny/daily.cs\" # API Call for NY data\n",
    "\n",
    "try:\n",
    "    s = requests.get(url).content\n",
    "    df = pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "\n",
    "    if df.values.size < 3:  # ensure DF has values (may just contain 2 error values)\n",
    "        raise FileNotFoundError(\"No data in API\")\n",
    "    else:\n",
    "        df.to_csv('ny_covid_data.csv', index=False)  # future proof in case api goes down\n",
    "        df = pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "\n",
    "except FileNotFoundError as fnf_error:\n",
    "    df = pd.read_csv(\"ny_covid_data.csv\")  # read from most recently fetched data\n",
    "except: # catch any other unexpected error\n",
    "    df = pd.read_csv(\"ny_covid_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Format dates\n",
    "df['date'] =  pd.to_datetime(df['date'], format='%Y%m%d') \n",
    "\n",
    "# Impute NaN values\n",
    "# df.fillna(value=-1, inplace=True)\n",
    "\n",
    "# apply filter on date\n",
    "df = df[df['date'] <= '2020-06-30']\n",
    "# df = df[df['date'] <= '2020-12-30']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasource 3 (CDC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import request\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "\n",
    "response=request(url='https://data.cdc.gov/id/vbim-akqf.json?current_status=Laboratory-confirmed%20case', method='get')\n",
    "covid_records_cdc = response.json()\n",
    "cdc_df = pd.DataFrame(covid_records_cdc)\n",
    "format_dt = '%Y-%m-%dT%H:%M:%S.%f'\n",
    "format_dt2 = '%Y-%m-%d'\n",
    "# Format dates\n",
    "pd.to_datetime(cdc_df['cdc_case_earliest_dt'], format=format_dt)\n",
    "pd.to_datetime(cdc_df['cdc_report_dt'], format=format_dt)\n",
    "pd.to_datetime(cdc_df['pos_spec_dt'], format=format_dt)\n",
    "cdc_df['cdc_case_earliest_dt']=pd.to_datetime(cdc_df['cdc_case_earliest_dt'], format=format_dt2)\n",
    "cdc_df['cdc_report_dt']=pd.to_datetime(cdc_df['cdc_report_dt'], format=format_dt2)\n",
    "cdc_df['pos_spec_dt']=pd.to_datetime(cdc_df['pos_spec_dt'], format=format_dt2)\n",
    "cdc_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result: Since the data source doesn't provide the location of the patient, we won't be able to use it for our current analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC Holiday calendar dataset for 2020\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "holiday_data = {'date': ['2020-01-01','2020-01-20','2020-02-17','2020-05-25','2020-06-30','2020-09-07','2020-10-12','2020-11-03','2020-11-11','2020-11-26','2020-12-25'],\n",
    "\t\t'Holiday': ['New Year Day','Martin Luther King Jr. Day', 'Presidents Day', 'Memorial Day', 'Independence Day(Observed)','Labor Day','Columbus Day','Election Day','Veterans Day','Thanksgiving day','Christmas Day' ],\n",
    "        'is_holiday':['1','1','1','1','1','1','1','1','1','1','1'],\n",
    "\t\t'is_long_weekend':['0','1','1','1','1','1','1','0','0','1','1']\n",
    "\t\t}\n",
    "\n",
    "calendar_df = pd.DataFrame (holiday_data, columns = ['date','Holiday','is_holiday','is_long_weekend'])\n",
    "\n",
    "calendar_df['date'] =  pd.to_datetime(calendar_df['date'], format='%Y-%m-%d')  \n",
    "df2 = df.set_index('date').join(calendar_df.set_index('date'))\n",
    "\n",
    "df2['is_holiday'].fillna('0',inplace=True)\n",
    "df2['is_long_weekend'].fillna('0', inplace=True) \n",
    "\n",
    "df2.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MTA travel stats for 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta_df = pd.read_csv('MTA_data.csv',index_col=[0], parse_dates=[0])\n",
    "\n",
    "\n",
    "mta_df = mta_df[[ 'Subways: Total Estimated Ridership']] \n",
    " \n",
    "mta_df['Subways: Total Estimated Ridership'] = pd.to_numeric(mta_df['Subways: Total Estimated Ridership'])\n",
    "\n",
    "mta_df.columns = ['Ridership']\n",
    "mta_df.plot()\n",
    "\n",
    "df2.join(mta_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "## Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are columns that don't have a significant impact to our analysis, namely date checked and date modified features. These columns we want to exclude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(['dateChecked', 'dateModified'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set a threshold of to tolerate up to 90% of values being NA per column. If a column contains more than 90% of NA values we drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.info\n",
    "limitPer = len(df) * .90\n",
    "df = df.dropna(thresh=limitPer, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also many features that just have zeros in them, we want to exclude that in our set as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = df.loc[:, (df != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ended up excluding 20 columns that just contained NA values, 2 columns that didn't have significant information (date modified and date checked), and 6 columns that only contained zeros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Plots\n",
    "In this first plot we can see the daily number of positive cases in NY from March 2020 - June 30, 2020:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_var('positiveIncrease')\n",
    "\n",
    "totalCases = \"{:,.0f}\".format(df['positiveIncrease'].sum())\n",
    "\n",
    "md(f\"In total there were {totalCases} positive cases in New York during that time range.\")\n",
    "# df.tail(n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following plots also show the increases in hospitalizations, deaths, and the total amount of test results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_var('hospitalizedIncrease')\n",
    "\n",
    "plot_var('deathIncrease')\n",
    "\n",
    "plot_var('totalTestResultsIncrease')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 56)\n",
    "\n",
    "# 7 days moving average for positiveIncrease\n",
    "df.sort_values(by=['date'], inplace=True, ascending=True)\n",
    "\n",
    "# reset index\n",
    "df.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots on 7-Day Moving Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_sevenday_newCases(df)\n",
    "add_sevenday_hospitalize(df)\n",
    "add_sevenday_death(df)\n",
    "add_sevenday_testResult(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_var('sevenDayAvg_newCases')\n",
    "plot_var('sevenDayAvg_hospitalize')\n",
    "plot_var('sevenDayAvg_death')\n",
    "plot_var('sevenDayAvg_testResult')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist('positiveIncrease')\n",
    "\n",
    "plot_hist('hospitalizedIncrease')\n",
    "\n",
    "plot_hist('deathIncrease')\n",
    "\n",
    "plot_hist('totalTestResultsIncrease')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "corrMatrix = df.corr()\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sb.heatmap(corrMatrix, annot=True, ax = ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's plain to see that death increases are positively correlated with hospitalizations and positive cases. It would also make sense that there would exist a negative correlations between deaths and total tests done, as the more informed the population is the better course of action they can take based on their status results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final State of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 2 \n",
    "\n",
    "Dataset provided by Johns Hopkins University Center for Systems Science and Engineering, here is github folder link for the dataset: https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series\n",
    "\n",
    "There are 424 columns present in the dataset, and the dates are present as columns. We can apply pivot on dates and convert columns to rows. We will delete unnecessary columns such as iso2,iso3, Country_Region, Lat, Long_, FIPS, Admin2, Combined_Key. Apply filter on Province_State i.e New York and timeline from March 2020 to June 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "df_jhu = pd.read_csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv\")\n",
    "# View data\n",
    "df_jhu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jhu_clean = pd.DataFrame(df_jhu)\n",
    "# Filter by New york state\n",
    "df_jhu_clean = df_jhu_clean[df_jhu_clean['Province_State'] == 'New York']\n",
    "# Timeline from March to June \n",
    "df_jhu_clean = df_jhu_clean.loc[:, '3/1/20':'6/30/20']\n",
    "# Check for Null value\n",
    "df_jhu_clean.isnull().values.any()\n",
    "# View Data\n",
    "df_jhu_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply reset index and calculate new cases from confirmed cases field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List for Columns \n",
    "column_list = df_jhu_clean.columns.tolist()\n",
    "# Convert columns to rows\n",
    "df2 = pd.melt(df_jhu_clean, value_vars= column_list, value_name=\"Confirmed_Cases\")\n",
    "# Change column name to Date\n",
    "df2.rename(columns = {'variable':'Dates'}, inplace = True)\n",
    "# Sum confirm cased and group by date\n",
    "df2 = pd.DataFrame(df2.groupby('Dates').sum())\n",
    "# reset index\n",
    "df2.reset_index(level=None, inplace=True) \n",
    "# Format Dates column\n",
    "df2['Dates'] =  pd.to_datetime(df2['Dates'], format='%m/%d/%y')\n",
    "# Order by Dates\n",
    "df2.sort_values(by=['Dates'], inplace=True, ascending=True)\n",
    "# View data\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Index\n",
    "df2.reset_index(level=None, drop=True, inplace=True)\n",
    "\n",
    "# Calculate New Cases per day\n",
    "def New_Cases(df2):\n",
    "    df2['New_Cases'] = 'NA'\n",
    "\n",
    "    for i in range(0, len(df2[\"Confirmed_Cases\"])):\n",
    "        if i == 0:\n",
    "            df2['New_Cases'][i] = 0\n",
    "        elif i > 0:\n",
    "            df2['New_Cases'][i]= df2['Confirmed_Cases'][i] - df2['Confirmed_Cases'][i-1] \n",
    "    return df2\n",
    "\n",
    "    \n",
    "# Call Function\n",
    "New_Cases(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph for Daily New cases\n",
    "def line_graph():\n",
    "    x = df2['Dates']\n",
    "    y = df2['New_Cases']\n",
    "    plt.figure(figsize=(20,4))\n",
    "    plt.title(\"Plot of \\\"{}\\\" for New York\".format(\"New Cases\"),fontsize=18)\n",
    "    plt.plot(x,y,color='navy')\n",
    "    plt.grid(False)\n",
    "    plt.xticks(fontsize=14,rotation=45)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.show()\n",
    "    \n",
    "line_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For daily Death and Recovered there are other files available in [this](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series) folder. If we use dataset 2 we need to go through data transformation. However, we are getting clean data from Tracking.com with all fields (daily cases, daily death, daily test result) in a single file, so we decide to use data from Tracking.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
